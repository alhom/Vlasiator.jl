<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Log · Vlasiator.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://henry2004y.github.io/Vlasiator.jl/log/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="Vlasiator.jl logo"/></a><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../examples/">User Guide</a></li><li><a class="tocitem" href="../internal/">API Reference</a></li><li class="is-active"><a class="tocitem" href>Log</a><ul class="internal"><li><a class="tocitem" href="#Precision"><span>Precision</span></a></li><li><a class="tocitem" href="#Performance"><span>Performance</span></a></li><li><a class="tocitem" href="#Memory"><span>Memory</span></a></li><li><a class="tocitem" href="#VTK"><span>VTK</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Log</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Log</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/henry2004y/Vlasiator.jl/blob/master/docs/src/log.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Log"><a class="docs-heading-anchor" href="#Log">Log</a><a id="Log-1"></a><a class="docs-heading-anchor-permalink" href="#Log" title="Permalink"></a></h1><h2 id="Precision"><a class="docs-heading-anchor" href="#Precision">Precision</a><a id="Precision-1"></a><a class="docs-heading-anchor-permalink" href="#Precision" title="Permalink"></a></h2><p>For post-processing and data analysis purposes, it makes less sense to stick to double precisions, so we consistently use <code>Float32</code> in Vlasiator.jl. (Not exactly, in fact in VDF plots we are still using double precision if <code>f</code> is saved in <code>Float64</code>.)</p><h2 id="Performance"><a class="docs-heading-anchor" href="#Performance">Performance</a><a id="Performance-1"></a><a class="docs-heading-anchor-permalink" href="#Performance" title="Permalink"></a></h2><p>The VLSV loader inherits the basic structure from <a href="https://github.com/fmihpc/analysator">Analysator</a> and is redesigned for performance.</p><ul><li>Besides the language difference in speed, one of the key decisions in boosting performance is to avoid the usage of dictionary with integer keys as much as possible.</li><li>It is generally faster to read a bunch of cell IDs together than to read each cell one-by-one.</li></ul><p>For development, it is recommended to use <a href="https://github.com/JuliaCI/PkgBenchmark.jl">PkgBenchmark.jl</a> to run the test suite:</p><pre><code class="nohighlight hljs">using PkgBenchmark, Vlasiator
results = benchmarkpkg(Vlasiator)</code></pre><p>or if you want to compare the current status of the package against a different git version</p><pre><code class="nohighlight hljs">judge(Vlasiator, &quot;97e3dca6b2474d7bdc5b62b5bf98ecf070516e5e&quot;)</code></pre><p>To export results to markdown format,</p><pre><code class="nohighlight hljs">export_markdown(&quot;testresult&quot;, results)</code></pre><p>See more in the PkgBenchmark <a href="https://juliaci.github.io/PkgBenchmark.jl/dev/">manual</a>.</p><h3 id="Benchmarks"><a class="docs-heading-anchor" href="#Benchmarks">Benchmarks</a><a id="Benchmarks-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmarks" title="Permalink"></a></h3><p>The numbers shown here are comparisons between Analysator v0.9 and Vlasiator.jl v0.1.</p><ul><li>Reading DCCRG grid variables</li></ul><table><tr><th style="text-align: left">Julia</th><th style="text-align: center">tmean [μs]</th><th style="text-align: left">Python</th><th style="text-align: center">tmean [μs]</th></tr><tr><td style="text-align: left">2MB</td><td style="text-align: center">200</td><td style="text-align: left">2MB</td><td style="text-align: center">1000</td></tr><tr><td style="text-align: left">50MB</td><td style="text-align: center">400</td><td style="text-align: left">50MB</td><td style="text-align: center">1000</td></tr></table><ul><li>Reading field solver grid<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> variables</li></ul><table><tr><th style="text-align: left">26GB</th><th style="text-align: center">tmean [s]</th></tr><tr><td style="text-align: left">Julia</td><td style="text-align: center">13</td></tr><tr><td style="text-align: left">Python</td><td style="text-align: center">45</td></tr></table><ul><li>From starting Julia/Python to the first plot<sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup></li></ul><table><tr><th style="text-align: left">2.3GB</th><th style="text-align: center">tmean [s]</th></tr><tr><td style="text-align: left">Julia</td><td style="text-align: center">11.6</td></tr><tr><td style="text-align: left">Python</td><td style="text-align: center">9.3</td></tr></table><ul><li>Reading and plotting one 2d slice of proton density out of 3D AMR data</li></ul><table><tr><th style="text-align: left">26GB</th><th style="text-align: center">tmean [s]</th></tr><tr><td style="text-align: left">Julia</td><td style="text-align: center">0.35</td></tr><tr><td style="text-align: left">Python</td><td style="text-align: center">1.7</td></tr></table><ul><li>Virtual satellite tracking from 845 frames of 3D AMR data (26G per frame) on a cluster</li></ul><table><tr><th style="text-align: left">1 CPU</th><th style="text-align: center">tmean [m]<sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup></th></tr><tr><td style="text-align: left">Julia</td><td style="text-align: center">11</td></tr><tr><td style="text-align: left">Python</td><td style="text-align: center">125</td></tr></table><h2 id="Memory"><a class="docs-heading-anchor" href="#Memory">Memory</a><a id="Memory-1"></a><a class="docs-heading-anchor-permalink" href="#Memory" title="Permalink"></a></h2><p>Vlasiator output files can be large. If we have limited memory relative to the file size, Vlasiator.jl provide direct hard disk mapping through <code>mmap</code> in Julia. With this mechanism you never need to worry about unable to process data with small free memory.</p><h2 id="VTK"><a class="docs-heading-anchor" href="#VTK">VTK</a><a id="VTK-1"></a><a class="docs-heading-anchor-permalink" href="#VTK" title="Permalink"></a></h2><p>VLSV is just an uncompressed binary format. If we convert VLSV to VTK through <code>write_vtk</code>, the generated VTK files, even the highest resolution one with every coarse cell mapping to the finest level, can be several times smaller than the original VLSV file.</p><p>One drawback of this conversion is that it cannot deal with phase space outputs, i.e. VDFs.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>The field solver grid is a regular Cartesian grid at the finest refinement level. Therefore the storage requirement for fsgrid variables are quite significant: with 16 GB memory it is barely enough to read <code>fg_b</code> once; it will go out of memory for the second time! This reading time corresponds to 35% of the maximum sequential read speed on the target machine.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>This inefficieny is a famous problem in the Julia community known as &quot;time to first plot&quot;. On the Python side, however, I don&#39;t know why using Analysator is slower (2.3GB file, 4.8s) than directly calling matplotlib functions (2.3GB file, 0.5s).</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>The timings are for a single CPU on Vorna, a local cluster at University of Helsinki with Intel Xeon CPUs. With multithreading, the Julia timings can scale linearly on a node with the number of cores used. For example, with 8 threads, Julia takes ~80s to finish.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../internal/">« API Reference</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.6 on <span class="colophon-date" title="Sunday 12 September 2021 19:10">Sunday 12 September 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
